---
layout: post
title:  "OS学习笔记4：CPU虚拟化的底层实现LDE"
date:   2019-08-11
tags: OS
color: rgb(255,102,51)
---

> 接下来讲一下底层的机制。

# 第六章 <机制：有限制的直接执行>

[PDF链接](http://pages.cs.wisc.edu/~remzi/OSTEP/cpu-mechanisms.pdf)

基本思路就是：执行一会儿这个，然后执行一会儿另一个。通过`分时共享time sharing`，CPU虚拟化就达成了。

但是有些挑战存在：

- `性能performance`：如何在不增加太多额外损耗的情况下实现？
- `控制control`：如何一边高效执行，一边又能控制？

OS经常要使用一些硬件支持，才能较好地实现上述目标。

## 6.1 基础技术：有限制的直接执行 Limited Direct Execution

`直接执行Direct Execution`很简单，就是前两章讲的进程的创建方式：

![Direct Execution](/static/blog/2019-08-11-DirectExcution.png)

这种模式下有两个问题：如何控制权限，如何暂停进程。

## 6.2 问题#1 限制操作 Restricted Operations

引入一个新的处理器模式`用户态user mode`，在用户态中运行的代码只能做它能做的事情。
比如，运行在用户态的进程不允许直接发起IO请求，否则处理器会报错，然后OS会把进程杀死。

相对立的是`内核态kernal mode`，在内核态中运行的代码可以进行任何操作。

现代的硬件允许用户调用`system call`，通过OS间接提供的约百个接口进行这些操作。

为了调用`system call`，程序必须执行一个特殊的`陷阱指令trap instruction`。这个指令同时跳转到内核并提升权限到内核态，此时可以执行任何操作。执行结束后，OS调用一个特殊的`陷阱返回指令return-from-trap`，返回到调用位置并同时将权限下降到用户态。

这个陷阱指令中，硬件必须非常小心，必须要保存足够的调用者的寄存器信息，来确保能正确地返回陷阱。
比如对于`x86`来说，处理器会将`程序计数器counter`，`标志flags`和一些其他的东西放进(push)这个进程特有的`内核栈kernel stack`中，从陷阱返回时则取出(pop)。

![Limited Direct Excution](/static/blog/2019-08-11-LimitedDirectExcution.png)

如何防止用户态程序从任意位置跳转到内核态？

OS在开机的时候会有一个`陷阱表trap table`，任何需要被控制的硬件都会被注册进去，并且OS也会在硬件中注册一些`异常处理的代码trap handlers`的位置（陷阱是异常之一），这样只有通过trap handlers才能操作已经注册了的硬件。

> 注意，虽然我们已经限定所有的systemcall必须经过指定的trapHandlers，但是用户依然可能通过systemCall的**参数**来进行恶意操作（就像在Web应用中常见的代码注入那样）。比如用户调用write()，但是参数是一个内核中的内存地址，那么内核中保存的信息就可能被写入硬盘，然后被用户态的代码读取。所以任何程序都必须检查用户输入，OS也不例外。

每个systemCall都被指定了一个`系统调用号码system-call number`，用户必须通过这个号码来调用systemCall，而不能直接指定内存地址。以此来进一步保护OS内核安全。

再强调一下，在硬件层面注册trapTable是非常强大的功能，如果用户态的程序想要强行接触硬件，硬件会拒绝，并且OS会杀死用户态程序。

> 思考：如果你可以任意操作trapTable，你能进而控制整台电脑吗？

## 6.3 问题#2 进程间切换 Switching Between Processes

看起来很简单，但是：当一个用户态进程在CPU上运行时，意味着OS是没有运行的，那么OS什么也做不了。

问题：OS如何夺回CPU控制权？

### 协作方法:等待系统调用 A Cooperative Approach: Wait For System Calls

古代的系统用这个方式：**相信**进程会时不时地调用systemCall，或者是发生异常崩溃了，此时OS就可以运行了，然后可以进行进程切换。

但是缺陷很明显：如果进程陷入无限循环怎么办？（或者进程在执行大规模的数学计算无法脱身？）

### 非协作方法：OS掌控一切 A Non-Cooperative Approach: The OS Takes Control

`计时打断器timer interrupt`：每隔一定时间引发一个中断，然后一个预先设定好的`中断处理程序interrupt handler`开始运行，这样OS就恢复控制了。它在开机时就开始运行了；它也可以被关闭，我们将在后面并发章节来说。

注意，当`中断interrupt`发生时（它也是一种异常），硬件必须支持这种异常，特别是必须要保存足够的上下文信息，这样之后的return-from-trap才能正确恢复当前进程。

### 保存和恢复上下文

当`调度器scheduler`决定要切换进程，OS就会执行一个底层代码叫做`上下文切换context switch`。做的事情很简单：把当前进程的寄存器数据保存起来（比如存到内核栈中），然后把下一个要执行的进程的寄存器数据取出来存入寄存器。

> 重启非常有用，有助于回收那些陈旧的或者泄露的资源，并且完全自动化。所以在大规模集群网络服务中，经常可以见到周期性地分批重启物理机器，以实现以上好处。所以，不要觉得**重启**是老古董，它其实是经过时间检验的提升性能的有效办法。

> 译者注：是的，我个人经验就是，周期性地**重启**的确对于设备性能有着明显的提升。比如我坚持每晚重启手机，每周重启办公室的电脑，很舒服。

![Timer Interrupt](/static/blog/2019-08-11-LDE-TimerInterrupt.png)

注意，以上有两种形式的寄存器数据存取。第一种是当timer interrupt发生时，**硬件**隐式地将**用户寄存器**储存在内核栈中。第二种是当OS决定切换进程时，**软件**显式地将**内核寄存器**保存在进程数据结构中。

## 6.4 担心并发

当一个中断或者陷阱发生时，另一个中断发生了怎么办？是的，OS的确要负责处理这种情况。我们将在本书的并发部分讲解。

说一些基础的：首先，OS会在处理一个中断的时候暂时`禁用中断disable interrupts`。另外，OS还有很多精巧的`锁locking`方案来保护内部数据结构在并发时的安全。

## 6.5 小结

我们描述了一些实现CPU虚拟化的关键底层机制，称为`limited direct execution`。基础思路就是在硬件上设置好，用户进程可以做哪些操作，而哪些操作必须由OS来做。

# 我的小结

一直说进程切换代价很大，如今看来的确是有一些代价的（对于寄存器等数据的频繁存取）。但是好像还没到点子上。后面应该能解答我的疑惑。

# Homework

## measure the cost of a system call

对C语言并不熟，于是根据网上搜的，分别用了`read()`函数和`fgets()`函数，读取文件中0个字节长度的数据。
个人感觉`0.3微秒`这个时间比较合理。

```c
// 读取0字节1m次,平均用时 0.314344 us
// 读取1字节100次，平均用时 5.620000 us
int mes_system_call_1()
{
    printf("Homework 1.1: measure the cost of a system call. using read().\n");
    char *buff = (char *)malloc(1024);
    int looptimes = 1000;
    int file_d = open("/usr/src/ostep-code/homework/ch6.cpp", O_RDONLY);

    struct timeval start;
    struct timeval end;
    gettimeofday(&start, NULL);
    for (int i = 0; i < looptimes; i++)
    {
        read(file_d, buff, 0);
    };
    gettimeofday(&end, NULL);
    long diff = 1000000 * (end.tv_sec - start.tv_sec) + end.tv_usec - start.tv_usec;
    // printf("Start time is %ld.%ld\n", start.tv_sec, start.tv_usec);
    // printf("End   time is %ld.%ld\n", end.tv_sec, end.tv_usec);
    printf("Duration is %ld, Loop %d tims, avg %f\n", diff, looptimes, (double)diff / looptimes);

    close(file_d);
    return 0;
}

// 读取0字节1m次,平均用时 0.008000 us
// 读取1字节100次，平均用时 3.830000 us
int mes_system_call_2()
{
    printf("Homework 1.2: measure the cost of a system call. using fgets().\n");
    char *buff = (char *)malloc(10);
    int looptimes = 1000;
    FILE *file_d = fopen("/usr/src/ostep-code/homework/ch6.cpp", "r");

    struct timeval start;
    struct timeval end;
    gettimeofday(&start, NULL);
    for (int i = 0; i < looptimes; i++)
    {
        fgets(buff, 1, file_d);
    };
    gettimeofday(&end, NULL);
    long diff = 1000000 * (end.tv_sec - start.tv_sec) + end.tv_usec - start.tv_usec;
    // printf("Start time is %ld.%ld\n", start.tv_sec, start.tv_usec);
    // printf("End   time is %ld.%ld\n", end.tv_sec, end.tv_usec);
    printf("Duration is %ld, Loop %d tims, avg %f\n", diff, looptimes, (double)diff / looptimes);

    fclose(file_d);
    return 0;
}
```

总感觉C语言怪怪的，于是还是掏出Golang写一版看一下：

```go
// 读取0字节1m次，平均用时 6.366280000000001e-08 s
// 读取1字节100次，平均用时 3.951e-06 s
func main() {
    fileDsc, e := os.Open("/go/src/Learning/run2.go")
    if e != nil {
        fmt.Println("Failed when open file.")
        return
    }
    defer fileDsc.Close()

    {
        var buf = make([]byte, 1)
        start := time.Now()
        for i := 0; i < 100; i++ {
            fileDsc.Read(buf)
        }
        totalTime := time.Since(start)
        fmt.Println(float64(totalTime.Seconds()) / 100)
    }
}
```

两个语言调用时间几乎相等(`6.0e-08`秒左右)，说明还是靠谱的。

### 附加题：空循环效率

为了实现**对照试验**的要求，我们要把空循环占用的时间给减去，以此求得循环内部代码的准确运行时间。

因此，分别在C语言和Go语言内写了一段代码，看一下空循环的运行时间：

```c
int main()
{
    int looptimes = 1000000;
    int count = 0;
    struct timeval start;
    struct timeval end;
    gettimeofday(&start, NULL);
    for (int i = 0; i < looptimes; i++)
    {
        // count+=i;
    };    
    gettimeofday(&end, NULL);
    long diff = 1000000 * (end.tv_sec - start.tv_sec) + end.tv_usec - start.tv_usec;
    printf("Duration is %ld, Loop %d tims, avg %f\n", diff, looptimes, (double)diff / looptimes);
}

// 编译命令 gcc -o xxx xxx.cpp
```

```go
func main() {
    {
        count := 0
        start := time.Now()
        for i := 0; i < 1000000; i++ {
            count +=i
        }
        totalTime := time.Since(start)
        fmt.Println(float64(totalTime.Seconds()) / 1000000)
        fmt.Println(count)
    }
}

// 编译命令go build xxx.go
```

完全一模一样的代码，几乎相等的机器（都在同一台电脑的Docker容器中运行，都限制了cpu=1），按道理来说，我们会觉得C语言应该效率更高吧，可是运行结果令我大吃一惊：

- `C` ：`2.406e-09`
- `Go` ： `5.714650000000001e-10`

为什么Go比C语言快了5倍？？

探究了一番，原来是因为**编译器优化**的问题，我试着加上编译优化参数：

```text
# gcc -O1 -o ch6 ch6.cpp
# ./ch6
Duration is 316, Loop 1000000 tims, avg 0.000316
# gcc -O2 -o ch6 ch6.cpp
# ./ch6
Duration is 1, Loop 1000000 tims, avg 0.000001
```

立马就快如闪电，快得过分了（哭笑不得），估计是`-O2`级优化时，编译器把这个循环改成了等差数列求和公式那样的`O(1)`级算法了。虽然没有具体了解其中的汇编实现，但是感觉`-O1`级别展现的`3.16e-9`这个时间比较合理（大概10个指令周期）。

## measure the cost of context switch

要测试上下文切换，那就一定要限制CPU为单核。而且不是限制CPU时间为1.0，而是只能限定于1个CPU，二者是不同的概念。

我这里用Docker的`--cpuset-cpus`参数来进行限定。

至于工具，书上提了一个`lmbench`这个东西，大概看了下好像有点猛，还是算了吧？

我们直接掏出Go：

```golang
// 主进程
func main() {
    cmd := exec.Command("./subprocess")
    cmdIn, _ := cmd.StdinPipe()
    cmdOut, _ := cmd.StdoutPipe()

    var buffR = make([]byte, 1)
    var buffW = []byte{'1'}
    var err error = cmd.Start();
    if err != nil {
       log.Fatal(err)
    }

    {
        start := time.Now()
        cmdIn.Write(buffW)
        for i := 0; i < 1000; i++ {
            cmdOut.Read(buffR)
            cmdIn.Write(buffW)
        }
        cmdOut.Read(buffR)
        totalTime := time.Since(start)
        fmt.Println(float64(totalTime.Seconds()) / 100)
    }
    cmd.Wait()
}
```

```golang
// 子进程
func main() {
    var buffR = make([]byte, 0)
    var buffW = []byte{}
    for i := 0; i < 1001; i++ {
        os.Stdin.Read(buffR)
        os.Stdout.Write(buffW)
    }
}
```

在缓冲区为1字节的情况下，平均运行时间`1.47958e-05`秒；
在缓冲区为0字节的情况下，平均运行时间`5.247e-07`秒；这个时间应该就是上下文切换的时间了，约一千多个指令周期。

### 附加题：Goruntine的切换效率

都说Goruntine是高效的协程，那么到底多高效？我们对比看一下：

```go
func main() {
    var ch = make(chan string, 1)
    go func() {
        for i := range ch {
            ch <- i
        }
    }()
    time.Sleep(time.Second)

    {
        start := time.Now()
        for i := 0; i < 1000000; i++ {
            ch <- ""
            <- ch
        }
        totalTime := time.Since(start)
        close(ch)
        fmt.Println(float64(totalTime.Seconds()) / 1000000)
    }
}

// ch传递0字符，运行输出 2.767679e-07
// ch传递1字符，运行输出基本不变
```

空数据传递的情况下，切换时间是0.2-0.3微秒，大概也就是进程上下文切换时间的一半左右。但是如果考虑到数据传递，那么`chan`就比`pipe`高效太多了（-5次方比-7次方，100倍）。
